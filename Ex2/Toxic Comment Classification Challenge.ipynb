{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification Challenge\n",
    "\n",
    "Kaggle Challenge: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "There is the train.csv and test.csv set. Since the test.csv has no labels we will concentrate on the train.csv set and apply cross-validation. \n",
    "You are provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:\n",
    "- toxic\n",
    "- severe_toxic\n",
    "- obscene\n",
    "- threat\n",
    "- insult\n",
    "- identity_hate\n",
    "\n",
    "You must create a model which predicts a probability of each type of toxicity for each comment.\n",
    "\n",
    "We use Pandas to load the data as it provied a nice ways to work with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7608</td>\n",
       "      <td>\"\\r\\n OK, I understand. -) I've been a racist ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44267</td>\n",
       "      <td>Hmm... vandalist brings up what I thought to b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112180</td>\n",
       "      <td>hey everyone User: Xeno sucks on mens dick!!!!!!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67617</td>\n",
       "      <td>Regarding edits made during March 8 2007 (UTC)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99209</td>\n",
       "      <td>In the unlikely event I accidentally picked tw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14096</td>\n",
       "      <td>Droop is not better than Hagenbach-Bischoff!!!...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70223</td>\n",
       "      <td>\"\\r\\n\\r\\n (watching) The template suggests tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25335</td>\n",
       "      <td>\"\\r\\n\\r\\n Blocked \\r\\n\\r\\n — xplicit \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54093</td>\n",
       "      <td>Then please add that source to here and mentio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>93746</td>\n",
       "      <td>\"\\r\\n\\r\\nTo  'This article deals with contenti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>76770</td>\n",
       "      <td>\"\\r\\nI also agree with the points raised above...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>129142</td>\n",
       "      <td>\"\\r\\n\\r\\nThe U.S. Treasury Department has the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11440</td>\n",
       "      <td>\" September 2010 (UTC)\\r\\nAnd disambiguation a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23157</td>\n",
       "      <td>\"\\r\\nPeople who claim that 9/11 was not perpet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23533</td>\n",
       "      <td>,because it isnt a sport</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>132368</td>\n",
       "      <td>Hello, you left me a message about my edit bei...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>707</td>\n",
       "      <td>\"::::::Agreed, although it means bloating the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6439</td>\n",
       "      <td>The other two users haven't used the account f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>122108</td>\n",
       "      <td>Reporting him, again. \\r\\n\\r\\nPlease ban him a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>74338</td>\n",
       "      <td>You suck DUCK BUTT! \\r\\n\\r\\nYEAH!!! lol</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                       comment_text  toxic\n",
       "0         7608  \"\\r\\n OK, I understand. -) I've been a racist ...      0\n",
       "1        44267  Hmm... vandalist brings up what I thought to b...      0\n",
       "2       112180  hey everyone User: Xeno sucks on mens dick!!!!!!!      1\n",
       "3        67617  Regarding edits made during March 8 2007 (UTC)...      0\n",
       "4        99209  In the unlikely event I accidentally picked tw...      0\n",
       "5        14096  Droop is not better than Hagenbach-Bischoff!!!...      0\n",
       "6        70223  \"\\r\\n\\r\\n (watching) The template suggests tha...      0\n",
       "7        25335             \"\\r\\n\\r\\n Blocked \\r\\n\\r\\n — xplicit \"      0\n",
       "8        54093  Then please add that source to here and mentio...      0\n",
       "9        93746  \"\\r\\n\\r\\nTo  'This article deals with contenti...      0\n",
       "10       76770  \"\\r\\nI also agree with the points raised above...      0\n",
       "11      129142  \"\\r\\n\\r\\nThe U.S. Treasury Department has the ...      0\n",
       "12       11440  \" September 2010 (UTC)\\r\\nAnd disambiguation a...      0\n",
       "13       23157  \"\\r\\nPeople who claim that 9/11 was not perpet...      0\n",
       "14       23533                           ,because it isnt a sport      0\n",
       "15      132368  Hello, you left me a message about my edit bei...      0\n",
       "16         707  \"::::::Agreed, although it means bloating the ...      0\n",
       "17        6439  The other two users haven't used the account f...      0\n",
       "18      122108  Reporting him, again. \\r\\n\\r\\nPlease ban him a...      0\n",
       "19       74338            You suck DUCK BUTT! \\r\\n\\r\\nYEAH!!! lol      1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame, read_csv\n",
    "\n",
    "train_df = read_csv('train_shuffled.csv')\n",
    "test_df = read_csv('test_shuffled.csv')\n",
    "train_df.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151890</td>\n",
       "      <td>\"\\r\\nHow is it a \"\"personal attack\"\" to point ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152979</td>\n",
       "      <td>\"\\r\\n{| style=\"\"background-color:#F5FFFA; padd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148234</td>\n",
       "      <td>(UTC)\\r\\n\\r\\nFirst, any 'numerology' regarding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65022</td>\n",
       "      <td>Ebyabe falsifies information on her repeated b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66534</td>\n",
       "      <td>\"\\r\\n\\r\\nSpeedy deletions\\r\\nHello! I recently...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30094</td>\n",
       "      <td>\"7 Sep 2012 ==\\r\\n As of 2012, 800,000 Rohingy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>148805</td>\n",
       "      <td>REDIRECT Talk:Bombardments of Shimonoseki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64216</td>\n",
       "      <td>\"\\r\\n\\r\\nSuggestion The new name should be:Cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>121596</td>\n",
       "      <td>Autor \\r\\n\\r\\nHi, who was the autor of this pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>117023</td>\n",
       "      <td>Fuck FINLAY McWALTER hes a faggot and he needs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       comment_text\n",
       "0      151890  \"\\r\\nHow is it a \"\"personal attack\"\" to point ...\n",
       "1      152979  \"\\r\\n{| style=\"\"background-color:#F5FFFA; padd...\n",
       "2      148234  (UTC)\\r\\n\\r\\nFirst, any 'numerology' regarding...\n",
       "3       65022  Ebyabe falsifies information on her repeated b...\n",
       "4       66534  \"\\r\\n\\r\\nSpeedy deletions\\r\\nHello! I recently...\n",
       "5       30094  \"7 Sep 2012 ==\\r\\n As of 2012, 800,000 Rohingy...\n",
       "6      148805          REDIRECT Talk:Bombardments of Shimonoseki\n",
       "7       64216  \"\\r\\n\\r\\nSuggestion The new name should be:Cal...\n",
       "8      121596  Autor \\r\\n\\r\\nHi, who was the autor of this pi...\n",
       "9      117023  Fuck FINLAY McWALTER hes a faggot and he needs..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download GloVe Embeddings\n",
    "\n",
    "You may find pretrained versions of the GloVe embeddings here: https://nlp.stanford.edu/projects/glove/ However the Gensim library provides an API which lets you download smoe of these embeddings directly onto your Laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'dog', 0.9590820074081421),\n",
       " (u'monkey', 0.920357882976532),\n",
       " (u'bear', 0.914313793182373),\n",
       " (u'pet', 0.9108030796051025),\n",
       " (u'girl', 0.8880630731582642),\n",
       " (u'horse', 0.8872727155685425),\n",
       " (u'kitty', 0.8870542645454407),\n",
       " (u'puppy', 0.8867697715759277),\n",
       " (u'hot', 0.8865255117416382),\n",
       " (u'lady', 0.8845518827438354)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "info = api.info()  # show info about available models/datasets\n",
    "model = api.load(\"glove-twitter-25\")  # download the model and return as object ready for use\n",
    "model.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.904156\n",
       "1    0.095844\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "We use the average of the word-embeddings in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Size: 127656 x 25\n"
     ]
    }
   ],
   "source": [
    "#size of the training input\n",
    "embedding_dimension = model['cat'].shape[0]\n",
    "nsamples = train_df['comment_text'].shape[0]\n",
    "\n",
    "print('Input Size: {} x {}'.format(nsamples, embedding_dimension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def tokenize_comments(df):\n",
    "    tokenized_comments = []\n",
    "    for comment in df['comment_text']:\n",
    "        tokens = simple_preprocess(comment, deacc=False, min_len=2, max_len=15)\n",
    "        tokenized_comments.append(tokens)\n",
    "    return tokenized_comments\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#compute average word embedding\n",
    "dummy_embedding = np.random.randn(embedding_dimension)\n",
    "\n",
    "def compute_avg_wemb(tokenized_comments):\n",
    "    nsamples = len(tokenized_comments)\n",
    "    X_data = np.zeros(shape=(nsamples, embedding_dimension))\n",
    "    for i, tokens in enumerate(tokenized_comments):\n",
    "        sentence_vectors = []\n",
    "        for token in tokens:\n",
    "            if model.vocab.get(token, None) is not None:\n",
    "                vec = model.get_vector(token)\n",
    "            else:\n",
    "                vec = dummy_embedding\n",
    "            sentence_vectors.append(vec)\n",
    "        if len(sentence_vectors) > 0:\n",
    "            sentence_array = np.array(sentence_vectors)\n",
    "            avg_vector = np.mean(sentence_array, axis=0)\n",
    "        else: \n",
    "            avg_vector = np.zeros(embedding_dimension)    \n",
    "        X_data[i] = avg_vector\n",
    "        assert not np.isnan(avg_vector).any()\n",
    "    return X_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127656\n",
      "31915\n"
     ]
    }
   ],
   "source": [
    "#create labels\n",
    "tokenized_train = tokenize_comments(train_df)\n",
    "X_train = compute_avg_wemb(tokenized_train)\n",
    "y_train = train_df['toxic']\n",
    "\n",
    "print(len(tokenized_train))\n",
    "print(len(tokenized_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = tokenize_comments(test_df)\n",
    "X_test = compute_avg_wemb(tokenized_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Random Scores:', 0.16155380057571378)\n",
      "('All One Score:', 0.1749219034819967)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "#ranomd baseline\n",
    "scores = []\n",
    "for i in range(5):\n",
    "    y_pred = np.random.randint(0, 2, size=y_train.shape)\n",
    "    scores.append(f1_score(y_train, y_pred, average='binary', pos_label=1))\n",
    "print('Random Scores:', np.mean(scores))\n",
    "\n",
    "#all_one baseline\n",
    "y_pred = np.ones(shape=y_train.shape)\n",
    "print('All One Score:', f1_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43026316 0.43939146 0.43855897 0.45008237 0.4281457 ]\n",
      "(0.4372883319836912, 0.00778030879009286)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf_gaussnb = GaussianNB()\n",
    "scores = cross_val_score(clf_gaussnb, X_train, y_train, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit classifier to training data\n",
    "clf_gaussnb.fit(X_train, y_train)\n",
    "y_pred = clf_gaussnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151890</td>\n",
       "      <td>\"\\r\\nHow is it a \"\"personal attack\"\" to point ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152979</td>\n",
       "      <td>\"\\r\\n{| style=\"\"background-color:#F5FFFA; padd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148234</td>\n",
       "      <td>(UTC)\\r\\n\\r\\nFirst, any 'numerology' regarding...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65022</td>\n",
       "      <td>Ebyabe falsifies information on her repeated b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66534</td>\n",
       "      <td>\"\\r\\n\\r\\nSpeedy deletions\\r\\nHello! I recently...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30094</td>\n",
       "      <td>\"7 Sep 2012 ==\\r\\n As of 2012, 800,000 Rohingy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>148805</td>\n",
       "      <td>REDIRECT Talk:Bombardments of Shimonoseki</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64216</td>\n",
       "      <td>\"\\r\\n\\r\\nSuggestion The new name should be:Cal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>121596</td>\n",
       "      <td>Autor \\r\\n\\r\\nHi, who was the autor of this pi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>117023</td>\n",
       "      <td>Fuck FINLAY McWALTER hes a faggot and he needs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28956</td>\n",
       "      <td>\"Hi, I am a Japanese  Will somebody edit \"\"thr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>154751</td>\n",
       "      <td>I realized that before I added the second para...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>63138</td>\n",
       "      <td>\"'' · Talk page · Contributions · Edit count ·...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>129817</td>\n",
       "      <td>Sorry, the rnw.nl link doesn't talk about Moha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>33697</td>\n",
       "      <td>\"\\r\\n\\r\\nKarofsky\\r\\nCan Karofsky get his his ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>142792</td>\n",
       "      <td>DuckDuckGo svg logo \\r\\n\\r\\nNow that DuckDuckG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>104289</td>\n",
       "      <td>\"\\r\\n\\r\\n Explain \\r\\nWhat \"\" test edits \"\" di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>121949</td>\n",
       "      <td>\"\\r\\n\\r\\n Mountain infobox style \\r\\n\\r\\nHello...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>49138</td>\n",
       "      <td>\"\\r\\nHope everything has been going well. I am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12783</td>\n",
       "      <td>You can't even shoot a fart outta yer own arse...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                       comment_text  toxic\n",
       "0       151890  \"\\r\\nHow is it a \"\"personal attack\"\" to point ...      0\n",
       "1       152979  \"\\r\\n{| style=\"\"background-color:#F5FFFA; padd...      0\n",
       "2       148234  (UTC)\\r\\n\\r\\nFirst, any 'numerology' regarding...      0\n",
       "3        65022  Ebyabe falsifies information on her repeated b...      1\n",
       "4        66534  \"\\r\\n\\r\\nSpeedy deletions\\r\\nHello! I recently...      0\n",
       "5        30094  \"7 Sep 2012 ==\\r\\n As of 2012, 800,000 Rohingy...      0\n",
       "6       148805          REDIRECT Talk:Bombardments of Shimonoseki      1\n",
       "7        64216  \"\\r\\n\\r\\nSuggestion The new name should be:Cal...      0\n",
       "8       121596  Autor \\r\\n\\r\\nHi, who was the autor of this pi...      0\n",
       "9       117023  Fuck FINLAY McWALTER hes a faggot and he needs...      1\n",
       "10       28956  \"Hi, I am a Japanese  Will somebody edit \"\"thr...      0\n",
       "11      154751  I realized that before I added the second para...      0\n",
       "12       63138  \"'' · Talk page · Contributions · Edit count ·...      0\n",
       "13      129817  Sorry, the rnw.nl link doesn't talk about Moha...      0\n",
       "14       33697  \"\\r\\n\\r\\nKarofsky\\r\\nCan Karofsky get his his ...      0\n",
       "15      142792  DuckDuckGo svg logo \\r\\n\\r\\nNow that DuckDuckG...      0\n",
       "16      104289  \"\\r\\n\\r\\n Explain \\r\\nWhat \"\" test edits \"\" di...      0\n",
       "17      121949  \"\\r\\n\\r\\n Mountain infobox style \\r\\n\\r\\nHello...      0\n",
       "18       49138  \"\\r\\nHope everything has been going well. I am...      0\n",
       "19       12783  You can't even shoot a fart outta yer own arse...      1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correct format for submission\n",
    "test_df['toxic'] = y_pred.tolist()\n",
    "test_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save results to csv\n",
    "test_df.to_csv('test_solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:KI2_FS2018]",
   "language": "python",
   "name": "conda-env-KI2_FS2018-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
